import streamlit as st
import mysql.connector
import pandas as pd
from mysql.connector import Error
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import os



# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏Ñ‡∏ä‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
@st.cache_resource
def get_db_connection():
    try:
        db_config = st.secrets["db_config"]
        required_keys = ["host", "database", "user", "password"]
        if not all(key in db_config for key in required_keys):
            raise KeyError("Missing required keys in db_config")
        conn = mysql.connector.connect(**db_config)
        return conn
    except (Error, KeyError) as e:
        if "is_initial_load" in st.session_state and st.session_state.is_initial_load:
            st.toast(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}", icon="‚ùå")
        return None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
def fetch_data(_conn, query, params=None):
    try:
        cursor = _conn.cursor(dictionary=True)
        if params:
            cursor.execute(query, params)
        else:
            cursor.execute(query)
        data = cursor.fetchall()
        cursor.close()
        return pd.DataFrame(data)
    except Error as e:
        if "is_initial_load" in st.session_state and st.session_state.is_initial_load:
            st.toast(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}", icon="‚ùå")
        return None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏Ñ‡∏ä‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (2 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)
@st.cache_data(ttl=3600)  # ‡πÅ‡∏Ñ‡∏ä 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
def fetch_recent_data(_conn, query, start_date, end_date):
    return fetch_data(_conn, query, (start_date, end_date))

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏µ‡∏û.‡∏®. ‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ.‡∏®.
def convert_to_ad(date):
    current_year = datetime.now().year
    if pd.isna(date):
        return date
    year = date.year
    if year > (current_year + 2):  # ‡∏ñ‡πâ‡∏≤‡∏õ‡∏µ‡πÄ‡∏Å‡∏¥‡∏ô‡∏õ‡∏µ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô +2 ‡∏õ‡∏µ ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏û.‡∏®.
        return date.replace(year=year - 543)
    return date

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
def phc_clean_data(df):
    df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y', errors='coerce')
    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà Date ‡∏°‡∏µ‡∏õ‡∏µ‡∏ô‡πâ‡∏≠‡∏ô‡∏Å‡∏ß‡πà‡∏≤ 2010
    df = df[df['Date'].dt.year >= 2010]
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
    numeric_cols = ["Qty", "Price", "Total", "WelfareB"]
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    df.dropna(subset=["Date"], inplace=True)
    df["Date"] = df["Date"].apply(convert_to_ad)
    return df

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå Parquet ‡πÅ‡∏•‡∏∞ CSV
def save_to_files(df, parquet_filename="sales_data.parquet", csv_filename="sales_data.csv", show_notification=False):
    try:
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô Parquet
        df.to_parquet(parquet_filename, index=False)
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô CSV
        df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
        if show_notification:
            st.toast(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå '{parquet_filename}' ‡πÅ‡∏•‡∏∞ '{csv_filename}' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à", icon="‚úÖ")
    except Exception as e:
        if show_notification:
            st.toast(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå: {e}", icon="‚ùå")

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Parquet
def load_from_parquet(filename="sales_data.parquet"):
    try:
        if os.path.exists(filename):
            df = pd.read_parquet(filename)
            return df
        return None
    except Exception as e:
        if "is_initial_load" in st.session_state and st.session_state.is_initial_load:
            st.toast(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå: {e}", icon="‚ùå")
        return None

# ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á SQL ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
base_query = """
SELECT
  dallycall.DocNo,
  dallycall.xDate AS Date,
  item.NameTH,
  dallycall.ItemCode,
  dallycall.Qty,
  dallycall.UnitCode,
  item_unit.Unit_Name,
  dallycall.Price,
  dallycall.Total,
  dallycall.WelfareB,
  dallycall.AreaCode,
  dallycall.Cus_Code,
  customer.FName AS Name_Cus,
  customer.Prefix_Code,
  customer.Cus_Type,
  customer.Cus_Type_Sub,
  customer.IsLetter,
  customer.BedCapacity,
  customer.IsBedConfirm,
  customer.IsActive,
  customer_type.CT_Name,
  th_province.Name_Th AS province 
FROM
  dallycall
  INNER JOIN customer ON dallycall.Cus_Code = customer.Cus_Code
  INNER JOIN customer_type ON customer.Cus_Type = customer_type.CT_Code
  INNER JOIN customer_type_sub ON customer_type.CT_Code = customer_type_sub.Customer_Type_Code
  INNER JOIN item ON dallycall.ItemCode = item.Item_Code
  INNER JOIN item_unit ON dallycall.UnitCode = item_unit.Unit_Code
  INNER JOIN th_province
  INNER JOIN area ON th_province.Pv_Code = area.Pv_Code 
  AND dallycall.AreaCode = area.`Code` 
WHERE
  dallycall.IsCancel = 0 
  AND dallycall.AreaCode2 = "-"
"""

# Query ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤ (‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏Å‡πà‡∏≠‡∏ô 2 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)
historical_query = base_query + " AND dallycall.xDate <= %s"

# Query ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (2 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
recent_query = base_query + " AND dallycall.xDate BETWEEN %s AND %s"

def main():
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if "is_initial_load" not in st.session_state:
        st.session_state.is_initial_load = True
    else:
        st.session_state.is_initial_load = False

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    today = datetime.now().date()
    two_months_ago = (today - relativedelta(months=2)).replace(day=1) - timedelta(days=1)
    recent_start = two_months_ago + timedelta(days=1)

    # ‡∏î‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠
    conn = get_db_connection()
    if conn is None:
        st.stop()

    # ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    parquet_file = "sales_data.parquet"
    csv_file = "sales_data.csv"

    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏à‡∏≤‡∏Å Parquet (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    combined_df = load_from_parquet(parquet_file)
    if combined_df is None or combined_df.empty:
        combined_df = pd.DataFrame()

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if combined_df.empty and st.session_state.is_initial_load:
        with st.status("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤ (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å)...", expanded=False):
            historical_df = fetch_data(conn, historical_query, (two_months_ago,))
            if historical_df is None or historical_df.empty:
                st.toast("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î", icon="‚ö†Ô∏è")
                historical_df = pd.DataFrame()
            else:
                historical_df = phc_clean_data(historical_df)
                combined_df = historical_df
                save_to_files(combined_df, parquet_file, csv_file, show_notification=True)

    # ‡∏õ‡∏∏‡πà‡∏°  ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà
    if st.button("‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î", key="refresh_button"):
        with st.status("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î...", expanded=False):
            recent_df = fetch_data(conn, recent_query, (recent_start, today))  # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡∏ä
            if recent_df is None or recent_df.empty:
                st.toast("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î", icon="‚ö†Ô∏è")
                recent_df = pd.DataFrame()
            else:
                recent_df = phc_clean_data(recent_df)
                # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (2 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô) ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å combined_df ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà
                if not combined_df.empty:
                    combined_df = combined_df[combined_df["Date"].dt.date <= two_months_ago]
                # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
                combined_df = pd.concat([combined_df, recent_df], ignore_index=True)
                # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ã‡πâ‡∏≥ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô unique identifier
                combined_df = combined_df.drop_duplicates(subset=["DocNo", "Date", "Cus_Code", "ItemCode"], keep="last")
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ß‡∏°‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á Parquet ‡πÅ‡∏•‡∏∞ CSV
                save_to_files(combined_df, parquet_file, csv_file, show_notification=True)
            st.rerun()

    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÅ‡∏Ñ‡∏ä 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á)
    recent_df = fetch_recent_data(conn, recent_query, recent_start, today)
    if recent_df is None or recent_df.empty:
        if st.session_state.is_initial_load:
            st.toast("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î", icon="‚ö†Ô∏è")
        recent_df = pd.DataFrame()
    else:
        recent_df = phc_clean_data(recent_df)

    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÑ‡∏ü‡∏•‡πå (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÉ‡∏´‡∏°‡πà)
    if not recent_df.empty:
        # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (2 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô) ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å combined_df ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà
        if not combined_df.empty:
            combined_df = combined_df[combined_df["Date"].dt.date <= two_months_ago]
        # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        combined_df = pd.concat([combined_df, recent_df], ignore_index=True)
        # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ã‡πâ‡∏≥ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô unique identifier
        combined_df = combined_df.drop_duplicates(subset=["DocNo", "Date", "Cus_Code", "ItemCode"], keep="last")
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ß‡∏°‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á Parquet ‡πÅ‡∏•‡∏∞ CSV
        save_to_files(combined_df, parquet_file, csv_file, show_notification=st.session_state.is_initial_load)

    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ß‡∏° (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥)
    if not combined_df.empty:
        combined_df = phc_clean_data(combined_df)

    # ‡πÉ‡∏´‡πâ index ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 1 
    combined_df.index += 1
   
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    with st.expander("üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢", expanded=True):
        st.write("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå:")
        st.write(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {combined_df.shape[0].__format__(',.0f')}")
        st.dataframe(combined_df.head(100))

    
    # Sidebar ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á
    st.sidebar.header("üîç Filter")
    # ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    min_date = combined_df["Date"].min().date() if not combined_df.empty else today - timedelta(days=365)
    max_date = combined_df["Date"].max().date() if not combined_df.empty else today
    date_range = st.sidebar.date_input(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date,
        format="DD-MM-YYYY",
        key="date_range_filter"
    )
    # ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
    selected_item = st.sidebar.selectbox(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤",
        options=["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + list(combined_df["NameTH"].unique()),
        key="item_filter"
    )
    # ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
    selected_customer = st.sidebar.selectbox(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤",
        options=["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + list(combined_df["Name_Cus"].unique()),
        key="customer_filter"
    )
    # ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏Ç‡∏ï (AreaCode)
    selected_area = st.sidebar.selectbox(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ç‡∏ï",
        options=["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(list(combined_df["AreaCode"].unique())),
        key="area_filter"
    )

    # ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ filtered_df ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß
    filtered_df = combined_df.copy()
   
    # ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á
    if len(date_range) == 2:  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏ö
        start_date, end_date = date_range
        filtered_df = filtered_df[(filtered_df["Date"].dt.date >= start_date) & 
                                (filtered_df["Date"].dt.date <= end_date)]
    if selected_item != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
        filtered_df = filtered_df[filtered_df["NameTH"] == selected_item]
    if selected_customer != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
        filtered_df = filtered_df[filtered_df["Name_Cus"] == selected_customer]
    if selected_area != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
        filtered_df = filtered_df[filtered_df["AreaCode"] == selected_area]
    # ‡πÉ‡∏´‡πâ index ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 1 ‡∏ô‡∏±‡∏ö‡πÉ‡∏´‡∏°‡πà
    filtered_df = filtered_df.reset_index(drop=True)
    filtered_df.index += 1
 
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    st.write("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå:")
    st.write(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {combined_df.shape[0].__format__(',.0f')} ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß: {filtered_df.shape[0].__format__(',.0f')}")
    st.dataframe(filtered_df)

    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢
    st.subheader("‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢")
    a, b = st.columns(2)
    c, d = st.columns(2)
    e, f = st.columns(2)
    g, h = st.columns(2)

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏à‡∏≤‡∏Å filtered_df
    total_sales = filtered_df['Total'].sum() if not filtered_df.empty else 0
    total_orders = filtered_df['DocNo'].nunique() if not filtered_df.empty else 0
    unique_customers = filtered_df['Cus_Code'].nunique() if not filtered_df.empty else 0

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà
    if not filtered_df.empty and len(date_range) == 2:
        start_date, end_date = date_range
        # ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô filtered_df
        current_customers = set(filtered_df['Cus_Code'].unique())
        # ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô combined_df ‡∏Å‡πà‡∏≠‡∏ô start_date
        previous_customers = set(combined_df[combined_df["Date"].dt.date < start_date]['Cus_Code'].unique())
        # ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà = ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
        new_customers = len(current_customers - previous_customers)
    else:
        new_customers = 0

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì MTD, YTD, YoY, MoM ‡∏à‡∏≤‡∏Å combined_df
    current_month_start = today.replace(day=1)
    previous_month_end = current_month_start - timedelta(days=1)
    previous_month_start = previous_month_end.replace(day=1)
    current_year = today.year
    previous_year = current_year - 1
    current_year_start = today.replace(year=current_year, month=1, day=1)
    previous_year_start = today.replace(year=previous_year, month=1, day=1)
    previous_year_end = today.replace(year=previous_year)

    # MTD
    mtd_sales = combined_df[
        (combined_df["Date"].dt.date >= current_month_start) &
        (combined_df["Date"].dt.date <= today)
    ]['Total'].sum() if not combined_df.empty else 0

    # YTD
    ytd_sales = combined_df[
        (combined_df["Date"].dt.date >= current_year_start) &
        (combined_df["Date"].dt.date <= today)
    ]['Total'].sum() if not combined_df.empty else 0

    # YoY
    previous_year_sales = combined_df[
        (combined_df["Date"].dt.date >= previous_year_start) &
        (combined_df["Date"].dt.date <= previous_year_end)
    ]['Total'].sum() if not combined_df.empty else 0
    if previous_year_sales != 0:
        yoy_growth = ((ytd_sales - previous_year_sales) / previous_year_sales) * 100
    else:
        yoy_growth = 100 if ytd_sales > 0 else 0

    # MoM
    previous_month_sales = combined_df[
        (combined_df["Date"].dt.date >= previous_month_start) &
        (combined_df["Date"].dt.date <= previous_month_end)
    ]['Total'].sum() if not combined_df.empty else 0
    mom_change = mtd_sales - previous_month_sales

    # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å
    a.metric(
        label="‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°",
        value=f"{total_sales:,.2f} ‡∏ö‡∏≤‡∏ó",
        border=True
    )
    b.metric(
        label="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå",
        value=f"{total_orders:,}",
        border=True
    )
    c.metric(
        label="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà",
        value=f"{new_customers:,}",
        border=True
    )
    d.metric(
        label="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤",
        value=f"{unique_customers:,}",
        border=True
    )
    e.metric(
        label="MTD",
        value=f"{mtd_sales:,.2f} ‡∏ö‡∏≤‡∏ó",
        border=True
    )
    f.metric(
        label="YTD",
        value=f"{ytd_sales:,.2f} ‡∏ö‡∏≤‡∏ó",
        border=True
    )
    g.metric(
        label="YoY",
        value=f"{yoy_growth:.2f}%",
        border=True
    )
    h.metric(
        label="MoM",
        value=f"{mtd_sales:,.2f} ‡∏ö‡∏≤‡∏ó",
        delta=f"{mom_change:,.2f} ‡∏ö‡∏≤‡∏ó",
        border=True
    )

if __name__ == "__main__":
    main()