import streamlit as st
import mysql.connector
import pandas as pd
from mysql.connector import Error
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import os

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏Ñ‡∏ä‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
@st.cache_resource
def get_db_connection():
    try:
        db_config = st.secrets["db_config"]
        required_keys = ["host", "database", "user", "password"]
        if not all(key in db_config for key in required_keys):
            raise KeyError("Missing required keys in db_config")
        conn = mysql.connector.connect(**db_config)
        return conn
    except (Error, KeyError) as e:
        st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
        return None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
def fetch_data(_conn, query, params=None):
    try:
        cursor = _conn.cursor(dictionary=True)
        if params:
            cursor.execute(query, params)
        else:
            cursor.execute(query)
        data = cursor.fetchall()
        cursor.close()
        return pd.DataFrame(data)
    except Error as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
        return None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏Ñ‡∏ä‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (2 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)
@st.cache_data(ttl=3600)  # ‡πÅ‡∏Ñ‡∏ä 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
def fetch_recent_data(_conn, query, start_date, end_date):
    return fetch_data(_conn, query, (start_date, end_date))

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏µ‡∏û.‡∏®. ‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ.‡∏®.
def convert_to_ad(date):
    current_year = datetime.now().year
    if pd.isna(date):
        return date
    year = date.year
    if year > (current_year + 2):  # ‡∏ñ‡πâ‡∏≤‡∏õ‡∏µ‡πÄ‡∏Å‡∏¥‡∏ô‡∏õ‡∏µ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô +2 ‡∏õ‡∏µ ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏û.‡∏®.
        return date.replace(year=year - 543)
    if year < 2010: #‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ô‡∏±‡πâ‡∏ô‡∏≠‡∏≠‡∏Å
        return date.replace(year=year + 543) 
    return date

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
def phc_clean_data(df):
    df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y', errors='coerce')
    numeric_cols = ["Qty", "Price", "Total", "WelfareB"]
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    df.dropna(subset=["Date"], inplace=True)
    df["Date"] = df["Date"].apply(convert_to_ad)
    return df

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå Parquet
def save_to_parquet(df, filename="sales_data.parquet"):
    try:
        df.to_parquet(filename, index=False)
        st.success(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå '{filename}' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå: {e}")

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Parquet
def load_from_parquet(filename="sales_data.parquet"):
    try:
        if os.path.exists(filename):
            df = pd.read_parquet(filename)
            return df
        return None
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå: {e}")
        return None

# ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á SQL ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
base_query = """
SELECT
  dallycall.xDate AS Date,
  item.NameTH,
  dallycall.ItemCode,
  dallycall.Qty,
  dallycall.UnitCode,
  item_unit.Unit_Name,
  dallycall.Price,
  dallycall.Total,
  dallycall.WelfareB,
  dallycall.AreaCode,
  dallycall.Cus_Code,
  customer.FName AS Name_Cus,
  customer.Prefix_Code,
  customer.Cus_Type,
  customer.Cus_Type_Sub,
  customer.IsLetter,
  customer.BedCapacity,
  customer.IsBedConfirm,
  customer.IsActive,
  customer_type.CT_Name,
  th_province.Name_Th AS province 
FROM
  dallycall
  INNER JOIN customer ON dallycall.Cus_Code = customer.Cus_Code
  INNER JOIN customer_type ON customer.Cus_Type = customer_type.CT_Code
  INNER JOIN customer_type_sub ON customer_type.CT_Code = customer_type_sub.Customer_Type_Code
  INNER JOIN item ON dallycall.ItemCode = item.Item_Code
  INNER JOIN item_unit ON dallycall.UnitCode = item_unit.Unit_Code
  INNER JOIN th_province
  INNER JOIN area ON th_province.Pv_Code = area.Pv_Code 
  AND dallycall.AreaCode = area.`Code` 
WHERE
  dallycall.IsCancel = 0 
  AND dallycall.AreaCode2 = "-"
"""

# Query ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤ (‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏Å‡πà‡∏≠‡∏ô 2 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)
historical_query = base_query + " AND dallycall.xDate <= %s"

# Query ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (2 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
recent_query = base_query + " AND dallycall.xDate BETWEEN %s AND %s"

def main():
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    today = datetime.now().date()
    two_months_ago = (today - relativedelta(months=2)).replace(day=1) - timedelta(days=1)
    recent_start = two_months_ago + timedelta(days=1)

    # ‡∏î‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠
    conn = get_db_connection()
    if conn is None:
        st.stop()

    # ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    data_file = "sales_data.parquet"

    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πâ‡∏≠‡∏ô‡πÅ‡∏£‡∏Å (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå)
    if not os.path.exists(data_file):
        st.write("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤ (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å)...")
        historical_df = fetch_data(conn, historical_query, (two_months_ago,))
        if historical_df is None or historical_df.empty:
            st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î")
            historical_df = pd.DataFrame()
        else:
            historical_df = phc_clean_data(historical_df)
            save_to_parquet(historical_df, data_file)
    else:
        st.info("‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Parquet")

    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå
    combined_df = load_from_parquet(data_file)
    if combined_df is None or combined_df.empty:
        combined_df = pd.DataFrame()

    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÅ‡∏Ñ‡∏ä 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á)
    recent_df = fetch_recent_data(conn, recent_query, recent_start, today)
    if recent_df is None or recent_df.empty:
        st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î")
        recent_df = pd.DataFrame()
    else:
        recent_df = phc_clean_data(recent_df)

    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÑ‡∏ü‡∏•‡πå
    if not recent_df.empty:
        combined_df = pd.concat([combined_df, recent_df], ignore_index=True)
        # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ã‡πâ‡∏≥ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô unique identifier
        combined_df = combined_df.drop_duplicates(subset=["Date", "Cus_Code", "ItemCode"], keep="last")
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ß‡∏°‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
        save_to_parquet(combined_df, data_file)

    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ß‡∏° (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥)
    if not combined_df.empty:
        combined_df = phc_clean_data(combined_df)

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    st.write("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå:")
    st.write(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {combined_df.shape[0].__format__(',.0f')}")
    st.dataframe(combined_df.head(10))

    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏∏‡πà‡∏°‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    if st.button("‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤"):
        if os.path.exists(data_file):
            os.remove(data_file)
        st.experimental_rerun()

    # ‡πÑ‡∏°‡πà‡∏õ‡∏¥‡∏î connection ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ st.cache_resource ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ
    # Sidebar ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á
    st.sidebar.header("üîç Filter")
    # ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    min_date = combined_df["Date"].min().date() if not combined_df.empty else today - timedelta(days=365)
    max_date = combined_df["Date"].max().date() if not combined_df.empty else today
    date_range = st.sidebar.date_input(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date,
        format="DD-MM-YYYY",
        key="date_range_filter"
    )
    # ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
    selected_item = st.sidebar.selectbox(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤",
        options=["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + list(combined_df["NameTH"].unique()),
        key="item_filter"
    )
    selected_customer = st.sidebar.selectbox(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤",
        options=["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + list(combined_df["Name_Cus"].unique()),
        key="customer_filter"
    )

    # ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ filtered_df ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß
    filtered_df = combined_df.copy()

    # ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á
    if len(date_range) == 2:  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏ö
        start_date, end_date = date_range
        filtered_df = filtered_df[(filtered_df["Date"].dt.date >= start_date) & 
                                (filtered_df["Date"].dt.date <= end_date)]
    if selected_item != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
        filtered_df = filtered_df[filtered_df["NameTH"] == selected_item]
    if selected_customer != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
        filtered_df = filtered_df[filtered_df["Name_Cus"] == selected_customer]
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    st.write("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå:")
    st.write(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {combined_df.shape[0].__format__(',.0f')}")
    st.dataframe( filtered_df)

    
if __name__ == "__main__":
    main()